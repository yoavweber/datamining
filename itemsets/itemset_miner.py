import argparse
from typing import Tuple, Sequence

import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder


def _generate_frequent_itemsets(
    df: pd.DataFrame,
    min_support: float = 0.05,
    max_len: int | None = None,
    min_len: int = 1,
) -> pd.DataFrame:
    """Generate frequent itemsets using Apriori.

    Parameters
    ----------
    df : pd.DataFrame
        One-hot-encoded transactional data (bool/int 0-1).
    min_support : float, default 0.05
        Minimum itemset support threshold.
    max_len : int | None, optional
        Maximum size of itemsets to generate. ``None`` means no limit.
    min_len : int, default 1
        Minimum size of itemsets to keep.

    Returns
    -------
    pd.DataFrame
        DataFrame with columns ["support", "itemsets", "length"].
    """
    itemsets = apriori(df, min_support=min_support, use_colnames=True, max_len=max_len)
    itemsets["length"] = itemsets["itemsets"].apply(len)
    itemsets = itemsets[itemsets["length"] >= min_len]
    return itemsets


def _generate_association_rules(
    itemsets: pd.DataFrame,
    min_confidence: float = 0.2,
    metric: str = "confidence",
) -> pd.DataFrame:
    """Generate association rules from frequent itemsets.

    Parameters
    ----------
    itemsets : pd.DataFrame
        Frequent itemsets generated by :func:`_generate_frequent_itemsets`.
    min_confidence : float, default 0.2
        Minimum rule confidence.
    metric : {"confidence", "lift", "leverage", "conviction"}, default "confidence"
        Metric to use for evaluating rules.

    Returns
    -------
    pd.DataFrame
        Association rules sorted by the chosen metric.
    """
    rules = association_rules(itemsets, metric=metric, min_threshold=min_confidence)
    rules["rule_length"] = rules["antecedents"].apply(len) + rules["consequents"].apply(len)
    return rules


# -----------------------------------------------------------------------------
# Utility
# -----------------------------------------------------------------------------


def _transactions_to_onehot(transactions: Sequence[Sequence[str]]) -> pd.DataFrame:
    """Convert a collection of transactions to a one-hot encoded DataFrame.

    Parameters
    ----------
    transactions : Sequence[Sequence[str]]
        A nested list (or any sequence) where each inner sequence represents a
        single transaction containing item identifiers.

    Returns
    -------
    pd.DataFrame
        One-hot-encoded representation suitable for the Apriori algorithm.
    """
    te = TransactionEncoder()
    te_array = te.fit(transactions).transform(transactions)
    return pd.DataFrame(te_array, columns=te.columns_)


# -----------------------------------------------------------------------------
# Public API
# -----------------------------------------------------------------------------


def generate_and_print(
    data: pd.DataFrame | Sequence[Sequence[str]],
    min_support: float = 0.05,
    min_confidence: float = 0.2,
    max_len: int | None = None,
    min_len: int = 1,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """High-level helper to generate & print itemsets and rules.

    Parameters
    ----------
    data : pd.DataFrame | Sequence[Sequence[str]]
        Either a one-hot-encoded ``pandas`` DataFrame **or** a nested list
        (sequence of sequences) where each inner sequence is a transaction with
        plain item identifiers.
    min_support : float, default 0.05
        Minimum itemset support.
    min_confidence : float, default 0.2
        Minimum rule confidence.
    max_len : int | None, optional
        Max length of itemsets to generate.
    min_len : int, default 1
        Min length of itemsets to keep.

    Returns
    -------
    Tuple[pd.DataFrame, pd.DataFrame]
        (frequent_itemsets, association_rules)
    """
    # Accept both raw transactions and pre-encoded DataFrames
    if isinstance(data, pd.DataFrame):
        df = data
    else:
        df = _transactions_to_onehot(data)  # type: ignore[arg-type]

    itemsets = _generate_frequent_itemsets(df, min_support, max_len, min_len)
    rules = _generate_association_rules(itemsets, min_confidence)

    _print_itemsets(itemsets)
    _print_rules(rules)

    return itemsets, rules


def _print_itemsets(itemsets: pd.DataFrame) -> None:
    """Print frequent itemsets grouped by their size."""
    if itemsets.empty:
        print("No frequent itemsets found with the given parameters.")
        return

    print("==================== Frequent Itemsets ====================")
    for length in sorted(itemsets["length"].unique()):
        print(f"\n# Itemsets of size {length}")
        for _, row in itemsets[itemsets["length"] == length].sort_values("support", ascending=False).iterrows():
            items = ", ".join(sorted(row["itemsets"]))
            print(f"{items}: support = {row['support']:.4f}")


def _print_rules(rules: pd.DataFrame) -> None:
    """Print association rules grouped by their total size (antecedent + consequent)."""
    if rules.empty:
        print("No association rules found with the given parameters.")
        return

    print("\n==================== Association Rules ====================")
    for length in sorted(rules["rule_length"].unique()):
        print(f"\n# Rules with total size {length}")
        group = rules[rules["rule_length"] == length].sort_values("confidence", ascending=False)
        for _, row in group.iterrows():
            antecedent = ", ".join(sorted(row["antecedents"]))
            consequent = ", ".join(sorted(row["consequents"]))
            print(
                f"{antecedent} => {consequent}: "
                f"support = {row['support']:.4f}, "
                f"confidence = {row['confidence']:.4f}, "
                f"lift = {row['lift']:.4f}"
            )


# -----------------------------------------------------------------------------
# CLI entry-point (optional)
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    # Hardcoded transactions (Hebrew)
    transactions = [
        ['שוקולד', 'ביצים', 'חלב', 'לחם', 'גבינה', 'חמאה'],
        ['מיץ', 'ביצים', 'חלב', 'לחם', 'גבינה', 'חמאה'],
        ['שוקולד', 'יוגורט', 'לחם', 'גבינה'],
        ['שוקולד', 'פסטרמה', 'נקניק', 'לחם', 'חמאה'],
        ['נקניק', 'ביצים', 'לחם', 'סוכריות', 'גבינה'],
    ]

    generate_and_print(
        transactions,
        min_support=0.6,
        min_confidence=0.8,
    ) 